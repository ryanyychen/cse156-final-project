
CSE 156 Natural Language Processing 
11 - prompting
Instructor: Lianhui Qin 
Slides adapted from Yejin Choi, Graham Neubig and Joyce Chai 
1 
Recap 
CSE 156 NLP 2 Prompting
Few-shot Prompting (Brown+ 2021) 
■ Provide a few examples of the task together with the instruction 
Instruction Please classify movie reviews as 'positive' or ‘negative’. 
Input: I really don’t like this movie.  
Output: negative 
Examples 
Input: This movie is great! 
Output: positive 
Language Models are Few-Shot Learners, Brown et al. 2020)
3 
CSE 156 NLP Lecture 11: Prompting 
LMs are Sensitive to Small Changes in In-context Examples ■ Example ordering (Lu et al. 2021) ■ Label balance (Zhang et al. 2022) 
■ Label coverage (Zhang et al. 2022) 
4
CSE 156 NLP Lecture 10: Prompting 
But Effects are Sometimes Counter-intuitive(Min et al. 2022) 
■ Replacing correct labels with random labels sometimes barely hurts accuracy ■ More demonstrations can sometimes hurt accuracy 

5
CSE 156 NLP Lecture 11: Prompting 
Chain of Thought Prompting(Wei et al. 2022) ■ Get the model to explain its reasoning before making an answer 
■ Provides the model with adaptive computation time 
6
CSE 156 NLP Lecture 11: Prompting 
Unsupervised Chain-of-thought Prompting (Kojima et al. 2022) 
■ Just adding a prompt that encourages the model to explain decisions can induce reasoning 

■Note: GPT models reason even w/o specific instructions now (probably due to instruction tuning)
21 
CSE 156 NLP Lecture 11: Prompting 
Program-aided Language Models(Gao et al. 2022) 
• Using a program to generate 
outputs can be more precise 
than asking the LM to do so 
• Especially useful for numeric 
questions 
• See ChatGPT code interpreter, 
Bard code execution 
• (More on agents/tools later) 
8
CSE 156 NLP Lecture 11: Prompting 
ReAct Prompting (Yao et al. 2022) 
Thinks out loud by reasoning through the  problem. 
Takes specific actions based on that  reasoning, like searching for more information  or checking facts. 
Aside from the Apple Remote, what other devices can control the  program Apple Remote was originally designed to interact with?

CSE 156 NLP 9 Lecture 10: Prompting 
Persona-based Prompting (Tseng et al. 2024) 
• Role-playing: LMs act according to  
assigned personas (roles) under defined  
environments. 
• Personalization: LMs consider user  
personas to generate tailored responses 
Lecture 13 
CSE 156 NLP 10
Lecture 10: Prompting 
Persona-based Prompting (Tseng et al. 2024) 
• Advantages:  
• Increases engagement and provides  
specialized, context-aware responses 
• Application: 
• Recommendation systems, customer  
support, and specialized domains like  
medicine or law 
Lecture 13 
CSE595 - Natural Language Processing - Fall 2024 
Lecture 10: Prompting 
CSE 156 NLP 11
Self-Refinement Prompting (Madaan et al. 2023) 
• Definition 
• LMs revise their own outputs  
when presented with feedback  
generated by themselves. 
• Advantages 
• Reduces the likelihood of  
incorrect information or  
hallucinations in the final output.
Lecture 13 
CSE595 - Natural Language Processing - Fall 2024 
Lecture 10: Prompting 
CSE 156 NLP 12 
Gradient-based Search (Shin et al. 2020) 
• Automatically optimize arbitrary prompts based on existing words13 
CSE 156 NLP Lecture 10: Prompting 
Why Tools: Things LLMs are Bad At 
Numerical/symbolic operations 
1. Calculation 
2. Logic deduction 
3. Exact operations 
Knowledge not in their pretraining corpus 
1. Tail factual knowledge 
2. New information 
3. Private information 
Interaction with the external world 
1. Non natural language interfaces 
2. Physical world 
3. Environmental information (time, e.g.)
10 
CSE 156 NLP 14 Lecture 10: Prompting 
10 
CMU 11-667 Fall 2024 
What are Tools 

Common Tool Categories and Examples [1] 
12 
[1] Wang et al. 2024. What Are Tools Anyway? A Survey from the Language Model Perspective. CMU 11-667 Fall 2024 15 CSE 156 NLP
Lecture 10: Prompting 
How to Enable LLMs to Use Tools? 
Pretraining  
(with Code) 
Standard Pretraining  
with Program Codes  
as Part of the Corpus 
• 
Finetuning  
(Tool Learning) 
Specialized Tool  Learning Stage for  Target Tools
[2] Snihck et al. 2023. Toolformer: Language Models Can Teach Themselves to Use Tools 
CSE 156 NLP 16 Lecture 10: Prompting 13 
Tool Usage Performance 

Significantly Improving GPT’s Performances [2] 
• Using at Max 25k examples perAPI 
[2] CSE 156 NLP Snihck et al. 2023. Toolformer: Language Models Can Teach Themselves to Use Tools 1725
Lecture 10: Prompting 
Tool Use: Summary 
Why LLM needs tools and what are they 
● To aid LLMs on tasks beyond their ability 
● Mainly tools for knowledge, symbolic, and external environment operations 
How to make LLMs effective tool users 
● Existing LLMs with coding ability can be prompted to generate noisy tool calls 
● Leverage the noisy tool call ability to curate tool use data ● Finetune LLMs on the tool use data to enhance its abilities
CMU 11-667 Lecture 10: Prompting Fall 2024 18 CSE 156 NLP 
Design of Prompts 
■ Manual 
□ Configure a manual template based on the characteristics of the task ■ Automated search 
□ Search in discrete space 
□ Search in continuous space
CSE 156 NLP Lecture 11: Prompting 19 
Manual Engineering: Format 
■ Make sure that the format matches that of a trained model (e.g. chat format) 
This can have a large effect on models! (Sclar et al. 2023) ■ 

20
CSE 156 NLP Lecture 11: Prompting 
Manual Engineering: Instructions 
Instructions should be clear, concise and easy to understand Good 
■ 
examples: https://www.promptingguide.ai/introduction/tips ■ 
• Less Precise: 
• Explain the concept prompt engineering. Keep the explanation short, only a few sentences, and don't be too descriptive. 
• More Precise: 
• Use 2-3 sentences to explain the concept of prompt engineering to a high school student.
Similar to humans, but (right now) LMs don’t complain when you’re vague 
CSE 156 NLP Lecture 11: Prompting 21 


How will chemicals  
behave at equilibrium? 
Kc 
 means the equilibrium  
constant. 
Understanding of this certain  
chemistry reaction. 
SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models Wang et al., arXiv 2023.

For the given reaction: 
N2(g) + O2(g) → N2O(g) 
The equilibrium constant K_c is defined as follows: Kc=[N2O] ([N2] × [O2]) 
[N2] [O2] [N2O] 
where , , and are the molar  N2 O2 N2O 
concentrations of , , and respectively at  equilibrium. 
[N2] =2.80 × 10−4mol 
2.00L= 1.40 × 10−4M 
Kc 
Then plug these values into the formula for : Kc=(1.00 × 10−2) 
1.40 × 10−4 × 1.25 × 10−5= 5.71 × 106K

For the given reaction: 
N2(g) + O2(g) → N2O(g) 
The equilibrium constant K_c is defined as follows: Kc=[N2O] ([N2] × [O2]) 
[N2] [O2] [N2O] 
where , , and are the molar  N2 O2 N2O 
concentrations of , , and respectively at  equilibrium. 
[N2] =2.80 × 10−4mol 
2.00L= 1.40 × 10−4M 
Kc 
Then plug these values into the formula for : Kc=(1.00 × 10−2) 
1.40 × 10−4 × 1.25 × 10−5= 5.71 × 106K

For the given reaction: 
N2(g) + O2(g) → N2O(g) 
The equilibrium constant K_c is defined as follows: Kc=[N2O] 
([N2] × [O2]) 
[N2] [O2] [N2O] 
where , , and are the molar  N2 O2 N2O 
concentrations of , , and respectively at  equilibrium. 
[N2] =2.80 × 10−4mol 
2.00L= 1.40 × 10−4M 
Kc 
Then plug these values into the formula for : 
Equation balancing 
Correct format of theorem 
2N2(g) + O2(g) → 2N2O(g) 
Kc=[N2O]a 
([N2]b × [O2]c) 
Kc=(1.00 × 10−2) 
1.40 × 10−4 × 1.25 × 10−5= 5.71 × 106K 
Plug-ins
Kc=(1.00 × 10−2)2 
(1.40 × 10−4)2 × 1.25 × 10−5= 4.08 × 108K 

For the given reaction: 
N2(g) + O2(g) → N2O(g) 
The equilibrium constant K_c is defined as follows: 
Firstly, we need to balance the given reaction: 2N2(g) + O2(g) → 2N2O(g) 
The equilibrium constant K_c is defined as  
Kc=[N2O] 
([N2] × [O2]) 
[N2] [O2] [N2O] 
follows: 
Kc=[N2O]a ([N2]b × [O2]c) 
where , , and are the molar  N2 O2 N2O 
concentrations of , , and respectively at  equilibrium. 
[N2] =2.80 × 10−4mol 
2.00L= 1.40 × 10−4M 
Kc 
Then plug these values into the formula for : Kc=(1.00 × 10−2) 
1.40 × 10−4 × 1.25 × 10−5= 5.71 × 106K 
where a,b,c are the coefficients of different  matters and [*] is the molarity of *. 
[N2] =2.80 × 10−4mol 
2.00L= 1.40 × 10−4M 
Kc 
Plugin the values and solving for numerically  we get  
Kc=(1.00 × 10−2)2 
(1.40 × 10−4)2 × 1.25 × 10−5= 4.08 × 108K
StructChem: 
A structural approach that elicits chemistry reasoning in LLMs • Overview 
Why not retrieval? 
Chemistry problem Structured instruction 
F0 R0Formulae generation Reasoning Process 
Iterative Review and Refinement  
with certain strategy 
Formulae generation with  step-by-step reasoning  
Answer 
StructChem: 
A structural approach that elicits chemistry reasoning in LLMs • Formulae generation with step-by-step reasoning 
Chemistry problem 
At a particular temperature, a  2.00L flask at equilibrium  contains 2.8 × 10−4 mol N2, … 
Collected Formulae 

Structured instruction 
Please provide a clear and step 
by-step solution for a scientific  
problem in the categories of … 
Reasoning steps 
[Formulae 1]  
2N2(g) + O2(g) → 2N2O(g) 
[Step 1] …compute the molarity of … 
[Formulae 2] … 
Confidence score: 0.9 
[Step 2] … 
F0 R0Confidence score: 0.7 
Structured instruction 
Please provide a clear and step-by-step solution for a scientific problem in the categories of Chemistry. The problem will specify the unit of  measurement, which should not be included in the answer. Express the final answer as a decimal number with three digits after the decimal point.  Conclude the answer by stating “The answer is therefore \\boxed{[ANSWER]}.” 
For each instance, you need to three things. Firstly, for "formulae retrieval", you need to identify the formulae explicitly and implicitly entailed in the  problem context. Then there is a "reasoning/calculation process" where you are required to reason step by step based on the identified formulae  and problem context. Finally, conclude the answer. For each problem, the output format should incorporate the following components in the  corresponding format: 
**Formulae retrieval: ** 
[Formula 1] (the formula required to solve the problem) [Formula 2] (the second formula required to solve the problem, if any) ... 
[Formula n] (the n-th formula required to solve the problem, if any) 
**Reasoning/calculation process:** 
[step 1] (the first step for solving this problem) 
..... 
[step n] (the n-th step for solving the problem, if any) 
**Answer conclusion:** 
[answer] The answer is therefore \\boxed{[ANSWER]}. 
To clearly explain the task, we provide the following example: 
Problem: 
Assume that all gases are perfect and that data refer to 298.15 K unless  otherwise stated. Calculate the change in chemical potential of a perfect  gas when its pressure is increased isothermally from $1.8 \\mathrm{~atm} $ to $29.5 \\mathrm{~atm}$ at $40^{\\circ} \\mathrm{C}$. The unit of the  answer is $\\mathrm{kJ} \\mathrm{mol}^{-1}$. 
Response: 
In order to solve this problem, we will use the formula for the change in  chemical potential \( \Delta \mu \) of a perfect gas due to a change in  pressure. Given that the temperature is constant (isothermal), the  chemical potential of a perfect gas is given by: 
……
StructChem: 
A structural approach that elicits chemistry reasoning in LLMs • Overview 
Chemistry problem Structured instruction 
F0 R0Formulae generation Reasoning Process 
Iterative Review and Refinement  
with certain strategy 
Formulae generation with  step-by-step reasoning  
Answer 
Iterative Review and Refinement F0 R0 Cf0 Cr0
F0 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) 
Kc=[N2O] 
([N2] × [O2]) 
Iterative Review and Refinement 
Confidence score C0: 0.9
Reviewer 1 
R0 F (0.9) 0 F0 → F1 
[Formulae 1] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O] 
F0 Confidence score C0: 0.9 
[Formulae 2] 
([N2] × [O2]) 
Iterative Review and Refinement 
Higher
F1 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O]a 
([N2]b × [O2]c) 
Confidence score C1: 0.95 
Reviewer 1 
F (0.9) 0 F0 → F1 
R0 
C1 ≥ C0 C1 < C0 
F (0.95) 1 
Discard F1 
F0 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) 
Kc=[N2O] 
([N2] × [O2]) 
Iterative Review and Refinement 
Confidence score C0: 0.9 
F1 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O]a 
([N2]b × [O2]c) 
Higher 
Confidence score C1: 0.95 
Reviewer 1 
F (0.9) 0 F0 → F1 
R0 
Lower 
[Formulae 1] 
N2(g) + O2(g) → N2O(g) 
C1 ≥ C0 C1 < C0 
F2Reviewer 2 
[Formulae 2] 
Kc=[N2O]a ([N2]b × [O2]c) 
M(g) =mol(g) 
Confidence score C2: 0.70
F (0.95) 1 
Discard F1 
[Formulae 3]  
C(g) 
F1 → F2 
C2 ≥ C1 C2 < C1 
Discard F2 
…… 
[Formulae 1] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O] 
F0 Confidence score C0: 0.9 
[Formulae 2] 
([N2] × [O2]) 
Iterative Review and Refinement 
Higher 
F1 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O]a 
([N2]b × [O2]c) 
Confidence score C1: 0.95 
Reviewer 1 
F (0.9) 0 F0 → F1 
R0 
Lower 
[Formulae 1] 
F2 
N2(g) + O2(g) → N2O(g) 
C1 ≥ C0 C1 < C0 
Reviewer 2 
[Formulae 2] 
Kc=[N2O]a ([N2]b × [O2]c) 
M(g) =mol(g) 
Confidence score C2: 0.70 
F (0.95) 1 
Discard F1 
Fn 
[Formulae 3]  
…… 
…… 
C(g) 
…… 
…… 

Reviewer n 
F1 → F2 
C2 ≥ C1 C2 < C1
Discard F2 
…… 
Fn 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O] 
([N2] × [O2]) 
Fn, R0 
[Formulae 3] … 
—————————————————————————— [Step 1] First calculate the molarity of each gas based on  
Iterative Review and Refinement 
Reviewer 1 Fn, R0
Formulae 3, … [Step 2] … 
Confidence score C0: 0.76 
Fn, R0 → Fn, R1 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O] 
([N2] × [O2]) 
Iterative Review and Refinement 
Fn, R0 
[Formulae 3] … 
—————————————————————————— 
[Step 1] First calculate the molarity of each gas based on  Formulae 3, … 
Reviewer 1 
F (0.76) n, R0 
[Step 2] … 
[Formulae 1] [Formulae 2] 
Confidence score C0: 0.76 
Higher 
2N2(g) + O2(g) → 2N2O(g) 
Kc=[N2O] 
Fn, R0 → Fn, R1 
C1 ≥ C0 
C1 < C0
Fn, R1 
([N2] × [O2]) 
[Formulae 3] … 
F (0.83) n, R1 Discard R1 
—————————————————————————— [Step 1] Based on the balanced equation in Formulae 1, … 
Reviewer 2 
[Step 2] … 
Confidence score C1: 0.83 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O] 
([N2] × [O2]) 
Iterative Review and Refinement 
Fn, R0 
[Formulae 3] … 
—————————————————————————— 
[Step 1] First calculate the molarity of each gas based on  Formulae 3, … 
Reviewer 1 
F (0.76) n, R0 
[Step 2] … 
[Formulae 1] [Formulae 2] 
Confidence score C0: 0.76 
Higher 
2N2(g) + O2(g) → 2N2O(g) 
Kc=[N2O] 
Fn, R0 → Fn, R1 
C1 ≥ C0 
C1 < C0 
Fn, R1 
([N2] × [O2]) 
[Formulae 3] … 
F (0.83) n, R1 Discard R1 
—————————————————————————— [Step 1] Based on the balanced equation in Formulae 1, … 
Reviewer 2 
Fn, R1 → Fn, R2 
[Step 2] … 
…… 
Fn, Rn 
Confidence score C1: 0.83 
…… 
Fn, Rn 
C2 ≥ C1
…… 

0 
F (0.9) 0 F0 → F1 
R0 
F (0.76) n, R0 Fn, R0 → Fn, R1 
0 
C1 ≥ C0 C1 < C0 
C1 ≥ C0 
F (0.95) 1 
F1 → F2 
C2 ≥ C1 C2 < C1 
Discard F1 
C1 < C0 
F (0.83) n, R1 Discard R1 Fn, R1 → Fn, R2 
n 
…… Fn 
Discard F2 
…… 
Fn, Rn 
C2 ≥ C1 
…… 
n
Therefore, the answer is …. 
Experiments

Benchmark performance (GPT-3.5) Zero-shot setting 
40 
40 


30 
30 
20 
20 
10 
10 
0 
0 
quan chemmc atkins matter avg 
Few-shot setting 


quan chemmc atkins matter avg 
Performance improvement on  
few-shot setting is even larger
Direct Reasoning System Instruction CoT Struct Chem 
Benchmark performance (GPT-4) Zero-shot setting 
60 
47.5 35 
22.5 10 


quan chemmc atkins matter avg 
Effective, average of 30%  
improvement 
60 
47.5 35 
22.5 10 
Few-shot setting 


quan chemmc atkins matter avg 
StructChem works on both  
GPT-3.5 and GPT-4
Direct Reasoning System Instruction CoT Struct Chem 
Validating reasoning quality 
Huge improvement over baselines.
Llama-2-13B-chat 
40 
40 


30 
30 
20 
20 
10 
10 
0 
0 
quan chemmc atkins matter avg 
Vicuna-13B 


quan chemmc atkins matter avg 
Zero-shot Inference Instuction 
CoT-finetuned 
StructChem-finetuned 
Teach smaller open-sourced models how to reason: ● Chemistry problems generated by GPT-4 as input ● Reasoning processes generated by StructChem as output  
Ablations Zero-shot setting 
Few-shot setting 
50 
60 


40 
50 
40 
30 
20 
30 
10 
20 
quan chemmc atkins matter avg 


quan chemmc atkins matter avg 
Effectiveness of all  components.
w/o confidence score w/o iterative review w/o review for Formulae StructChem 
Error analysis 
Formulae collection 
● Irrelevance: irrelevant formulae collected  
to solving the problem.  
● Incorrectness: incorrectness inherent in  
the formula itself.  
Reasoning  
● Reasoning error: errors made during the  
intermediate reasoning steps.  
● Calculation error: mathematical  
computation mistakes made during  
reasoning process.Irrelevance Incorrectness Reasoning error Calculation error
Error analysis 
Formulae collection 
● Principle error: formulae collected are  
LLMs are more likely to be irrelevant than  
not relevant to solving the problem.  
inaccurate 
● Factual error: incorrectness inherent in  the formula itself.  
Reasoning  
Complex reasoning is still the bottleneck. 
● Reasoning error: errors made during the  intermediate reasoning steps.  
● Calculation error: mathematical  Calculation errors are a significant issue as well. 
computation mistakes made during  reasoning process. 
Summary 
(1) study the various ways the precise scientific reasoning can fail with frontier  LLMs  
(2) the importance of symbolic/structured reasoning 
(3) acknowledging that this type of precise reasoning remains to be a major  challenge, suggesting a more fundamental research into this direction
Thank you! 
CSE 156 NLP 48 
Prompting
