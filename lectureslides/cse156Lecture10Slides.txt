
CSE 156 Natural Language Processing 
10 - prompting
Instructor: Lianhui Qin 
Slides adapted from Yejin Choi, Graham Neubig and Joyce Chai 
1 
Recap 
CSE 156 NLP 2 Pretraining
Overview: The Paradigm Shift Training Set (Dev) 
Classic Deep Learning 
Train Development Set  
slow 
(Dev) 
Validation Set (Val) Validate 
Test Set (Test) Test 
Pre-training Set (Pre) 
Development Set  (Dev) 
Test Set (Test) 
Pre-training Set (Pre) 
Pre-train 
slow 
Pre-train 
slow 
Fine 
Test fast Tune 
Since 2018 (Elmo) Since 2020 (GPT-3) 
Test Set (Test) 
In-Context Learning (Zero-shot Learning) 
Test 
CSE 156 NLP 3
What is Prompting？ 
□ Encouraging a pre-trained model to make particular predictions by  providing a textual “prompt" specifying the task to be done.
4 
CSE 156 NLP Lecture 10: Prompting 
Basic Prompting (Radford et al. 2018) 
■ Complete a sentence 
x = When a dog sees a squirrel, it will usually 
(GPT-2 Small) 
be afraid of anything unusual. As an exception, that's when a squirrel is usually afraid to bite. 
(GPT-2 XL) lick the squirrel. It will also touch its nose to the squirrel on the tail  and nose if it can.
CSE 156 NLP 5 Lecture 9: Prompting+Chemistry_Reasoning 
Answer Prediction 
■ Given a prompt, predict the answer 
Prompting: x’ = “I love this movie. Overall it was [z]”

Predicting: x’ = “I love this movie. Overall it was fantastic” 
■ 
6 
Use any inference algorithms, as in generation class 
CSE 156 NLP Lecture 10: Prompting 
Output Formatting 
■ For user-facing applications, format in a pretty way 
Markdown Rendering Code 

7
CSE 156 NLP Lecture 10: Prompting 
Post-processing: Output Selection ■ From a longer response, select the information indicative of an answer 
Predicting: x’ = “I love this movie. Overall it was a movie that was simply fantastic”

Extraction: fantastic 
• Classification: identify keywords  
• Regression/numerical problems: identify numbers  
• Code: pull out code snippets in triple-backticks 
8 
CSE 156 NLP Lecture 10: Prompting 
Few-shot Prompting (Brown+ 2021) 
■ Provide a few examples of the task together with the instruction 
Instruction Please classify movie reviews as 'positive' or ‘negative’. 
Input: I really don’t like this movie.  
Output: negative 
Examples 
Input: This movie is great! 
Output: positive 
Language Models are Few-Shot Learners, Brown et al. 2020)
9 
CSE 156 NLP Lecture 10: Prompting 
LMs are Sensitive to Small Changes in In-context Examples ■ Example ordering (Lu et al. 2021) ■ Label balance (Zhang et al. 2022) 
■ Label coverage (Zhang et al. 2022) 
10
CSE 156 NLP Lecture 9: Prompting 
But Effects are Sometimes Counter-intuitive(Min et al. 2022) 
■ Replacing correct labels with random labels sometimes barely hurts accuracy ■ More demonstrations can sometimes hurt accuracy 

11
CSE 156 NLP Lecture 10: Prompting 
Chain of Thought Prompting(Wei et al. 2022) ■ Get the model to explain its reasoning before making an answer 
■ Provides the model with adaptive computation time 
12
CSE 156 NLP Lecture 10: Prompting 
Unsupervised Chain-of-thought Prompting (Kojima et al. 2022) 
■ Just adding a prompt that encourages the model to explain decisions can induce reasoning 

■Note: GPT models reason even w/o specific instructions now (probably due to instruction tuning)
21 
CSE 156 NLP Lecture 10: Prompting 
Structuring Outputs as Programs can Help(Madaan et al. 2022) 
• When predicting a structured  
output, using a programming  
language instead of natural  
language often increases accuracy 
• Why? Programs are highly 
structured and included in pre 
training data 
• Asking the model to generate  
JSON can help formatting problems 
14
CSE 156 NLP Lecture 10: Prompting 
Program-aided Language Models(Gao et al. 2022) 
• Using a program to generate 
outputs can be more precise 
than asking the LM to do so 
• Especially useful for numeric 
questions 
• See ChatGPT code interpreter, 
Bard code execution 
• (More on agents/tools later) 
15
CSE 156 NLP Lecture 10: Prompting 
ReAct Prompting (Yao et al. 2022) 
Thinks out loud by reasoning through the  problem. 
Takes specific actions based on that  reasoning, like searching for more information  or checking facts. 
Aside from the Apple Remote, what other devices can control the  program Apple Remote was originally designed to interact with?

Large Model Reasoning - CSE 291 16 Lecture 6: Pretraining+Chemistry_Reasoning 
ReAct Prompting (Yao et al. 2022) 
• Definition 
• LMs generate both reasoning traces and task specific actions in an interleaved manner 
• Advantages 
• Improved human interpretability and  
trustworthiness 
• Mitigating error propagation and hallucinations 
• Other use cases: 
• Scaling up ReAct for multi-task training 
• Combining with reinforcement learning paradigms 
Aside from the Apple Remote, what other devices can control the  program Apple Remote was originally designed to interact with?

Large Model Reasoning - CSE 291 17 Lecture 6: Pretraining+Chemistry_Reasoning 
Persona-based Prompting (Tseng et al. 2024) 
• Role-playing: LMs act according to  
assigned personas (roles) under defined  
environments. 
• Personalization: LMs consider user  
personas to generate tailored responses 
Lecture 1318
Large Model Reasoning - CSE 291 Lecture 6: Pretraining+Chemistry_Reasoning 
Persona-based Prompting (Tseng et al. 2024) 
• Advantages:  
• Increases engagement and provides  
specialized, context-aware responses 
• Application: 
• Recommendation systems, customer  
support, and specialized domains like  
medicine or law 
Lecture 1319CSE595 - Natural Language Processing - Fall 2024 
Large Model Reasoning - CSE 291 Lecture 6: Pretraining+Chemistry_Reasoning 
Self-Refinement Prompting (Madaan et al. 2023) 
• Definition 
• LMs revise their own outputs  
when presented with feedback  
generated by themselves. 
• Advantages 
• Reduces the likelihood of  
incorrect information or  
hallucinations in the final output.
Lecture 1320 
CSE595 - Natural Language Processing - Fall 2024 
Large Model Reasoning - CSE 291 Lecture 6: Pretraining+Chemistry_Reasoning 
Reference
• Other prominent prompting techniques can be found at: https:// www.promptingguide.ai/techniques 
• Survey: Pre-train, Prompt, and Predict: A Systematic Survey of Prompting  Methods in Natural Language Processing 
Lecture 1321 
CSE595 - Natural Language Processing - Fall 2024 
Large Model Reasoning - CSE 291 Lecture 6: Pretraining+Chemistry_Reasoning 
Gradient-based Search (Shin et al. 2020) 
• Automatically optimize arbitrary prompts based on existing words22 
Large Model Reasoning - CSE 291 Lecture 8: Prompting 
Tool Use 
23
Large Model Reasoning - CSE 291 Lecture 7: Prompting 
Why Tools 
LLMs are not the solution for everything. (Not AGI yet. Surprise?) 
O1 cannot solve multiplications of 10+ digits… Multiplication Accuracy of OpenAI O1 (Yuantian Deng, X) 
CMU 11-667 Fall 2024 24
Large Model Reasoning - CSE 291 Lecture 6: Pretraining+Chemistry_Reasoning 
Why Tools 
LLMs are not the solution for everything. (Not AGI yet. Surprise?) 
• O1 cannot solve multiplications of 10+ digits… 
• But does it really need to? 
• We humans can use a calculator to do it… 
Multiplication Accuracy of OpenAI O1 (Yuantian Deng, X) 
• So do LLMs 
CMU 11-667 Fall 2024 25
Large Model Reasoning - CSE 291 Lecture 6: Pretraining+Chemistry_Reasoning 
Why Tools: Things LLMs are Bad At 
Numerical/symbolic operations 
1. Calculation 
2. Logic deduction 
3. Exact operations 
Knowledge not in their pretraining corpus 
1. Tail factual knowledge 
2. New information 
3. Private information 
Interaction with the external world 
1. Non natural language interfaces 
2. Physical world 
3. Environmental information (time, e.g.)
10 
Large Model Reasoning - CSE 291 26 Lecture 6: Pretraining+Chemistry_Reasoning 
10 
CMU 11-667 Fall 2024 
What is a Tool for LLM? 
Definition: An LM-used tool is a function interface to a computer program that runs externally to the LM, where the LM generates the function calls and input arguments in order to use the tool [1] 
A tool is: 
• A Computer Program 
• External to the LM 
• Used through generated 
function calls
LLM with Tools [1] 
[1] Wang et al. 2024. What Are Tools Anyway? A Survey from the Language Model Perspective. 
11 
CMU 11-667 Fall 2024 27 
Large Model Reasoning - CSE 291 Lecture 6: Pretraining+Chemistry_Reasoning 
What are Tools 

Common Tool Categories and Examples [1] 
12 
[1] Wang et al. 2024. What Are Tools Anyway? A Survey from the Language Model Perspective. CMU 11-667 Fall 2024 28
Large Model Reasoning - CSE 291 Lecture 6: Pretraining+Chemistry_Reasoning 
How to Enable LLMs to Use Tools? 
Example Tool Usage from LLMs [2]: 
Function calls predicted by LLMs 
• Tool execute that function call 
• Returned results as part of LLMs context 
LLMs need to learn: 
• When to use tools 
• Which tool to use 
• 
• How to incorporate tool’s results
[2] Snihck et al. 2023. Toolformer: Language Models Can Teach Themselves to Use Tools 29 
Large Model Reasoning - CSE 291 Lecture 6: Pretraining+Chemistry_Reasoning 13 
How to Enable LLMs to Use Tools? 
Pretraining  
(with Code) 
Standard Pretraining  
with Program Codes  
as Part of the Corpus 
• 
Finetuning  
(Tool Learning) 
Specialized Tool  Learning Stage for  Target Tools
[2] Snihck et al. 2023. Toolformer: Language Models Can Teach Themselves to Use Tools 
Large Model Reasoning - CSE 291 30 Lecture 6: Pretraining+Chemistry_Reasoning 13 
Tool Usage Performance 

Significantly Improving GPT’s Performances [2] 
• Using at Max 25k examples perAPI 
[2] Snihck et al. 2023. Toolformer: Language Models Can Teach Themselves to Use Tools 3125
Large Model Reasoning - CSE 291 Lecture 6: Pretraining+Chemistry_Reasoning 
Tool Use: Summary 
Why LLM needs tools and what are they 
● To aid LLMs on tasks beyond their ability 
● Mainly tools for knowledge, symbolic, and external environment operations 
How to make LLMs effective tool users 
● Existing LLMs with coding ability can be prompted to generate noisy tool calls 
● Leverage the noisy tool call ability to curate tool use data ● Finetune LLMs on the tool use data to enhance its abilities
Large Model Reasoning - CSE 291 Lecture 6: Pretraining+Chemistry_Reasoning CMU 11-667 Fall 2024 32 
Prompt Engineering
CSE 156 NLP Lecture 9: Prompting 33 
Design of Prompts 
■ Manual 
□ Configure a manual template based on the characteristics of the task ■ Automated search 
□ Search in discrete space 
□ Search in continuous space
CSE 156 NLP Lecture 10: Prompting 34 
Manual Engineering: Format 
■ Make sure that the format matches that of a trained model (e.g. chat format) 
This can have a large effect on models! (Sclar et al. 2023) ■ 

35
CSE 156 NLP Lecture 10: Prompting 
Manual Engineering: Instructions 
Instructions should be clear, concise and easy to understand Good 
■ 
examples: https://www.promptingguide.ai/introduction/tips ■ 
• Less Precise: 
• Explain the concept prompt engineering. Keep the explanation short, only a few sentences, and don't be too descriptive. 
• More Precise: 
• Use 2-3 sentences to explain the concept of prompt engineering to a high school student.
Similar to humans, but (right now) LMs don’t complain when you’re vague 
CSE 156 NLP Lecture 10: Prompting 36 
Methods for Automatic Prompt Engineering 
• Prompt paraphrasing 
• Gradient-based discrete prompt search Prompt tuning • Prefix tuning
CSE 156 NLP Lecture 10: Prompting 37 
Prompt Paraphrasing 
• Paraphrase an existing prompt to get other candidates (Jiang et al. 2019) 
[X] shares a border with [Y]. 
Paraphrasing Model
[X] has a common border with [Y]. [X] adjoins [Y]. 
…… 
•Can be done through iterative paraphrasing (Zhou et al. 2021) 30 
CSE 156 NLP Lecture 10: Prompting 
Gradient-based Search (Shin et al. 2020) 
• Automatically optimize arbitrary prompts based on existing words 39
CSE 156 NLP Lecture 10: Prompting 
CSE 156 NLP 
Reasoning? 
40 Pretraining
StructChem:  

Structured Chemistry Reasoning with Large Language  Models 
Siru Ouyang Zhuosheng  
Zhang Bing Yan Xuan Liu Yejin Choi Jiawei Han Lianhui Qin 
ICML2024
Previous chemistry tasks

Previous chemistry tasks 
Direct question-answering;  
Lack complex reasoning process 


Unifying textual and molecule representation via multi-tasking.
Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models. Fang et al., arXiv 2306. 


How will chemicals  
behave at equilibrium? 
Kc 
 means the equilibrium  
constant. 
Understanding of this certain  
chemistry reaction. 
SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models Wang et al., arXiv 2023.

For the given reaction: 
N2(g) + O2(g) → N2O(g) 
The equilibrium constant K_c is defined as follows: Kc=[N2O] ([N2] × [O2]) 
[N2] [O2] [N2O] 
where , , and are the molar  N2 O2 N2O 
concentrations of , , and respectively at  equilibrium. 
[N2] =2.80 × 10−4mol 
2.00L= 1.40 × 10−4M 
Kc 
Then plug these values into the formula for : Kc=(1.00 × 10−2) 
1.40 × 10−4 × 1.25 × 10−5= 5.71 × 106K

For the given reaction: 
N2(g) + O2(g) → N2O(g) 
The equilibrium constant K_c is defined as follows: Kc=[N2O] ([N2] × [O2]) 
[N2] [O2] [N2O] 
where , , and are the molar  N2 O2 N2O 
concentrations of , , and respectively at  equilibrium. 
[N2] =2.80 × 10−4mol 
2.00L= 1.40 × 10−4M 
Kc 
Then plug these values into the formula for : Kc=(1.00 × 10−2) 
1.40 × 10−4 × 1.25 × 10−5= 5.71 × 106K

For the given reaction: 
N2(g) + O2(g) → N2O(g) 
The equilibrium constant K_c is defined as follows: Kc=[N2O] 
([N2] × [O2]) 
[N2] [O2] [N2O] 
where , , and are the molar  N2 O2 N2O 
concentrations of , , and respectively at  equilibrium. 
[N2] =2.80 × 10−4mol 
2.00L= 1.40 × 10−4M 
Kc 
Then plug these values into the formula for : 
Equation balancing 
Correct format of theorem 
2N2(g) + O2(g) → 2N2O(g) 
Kc=[N2O]a 
([N2]b × [O2]c) 
Kc=(1.00 × 10−2) 
1.40 × 10−4 × 1.25 × 10−5= 5.71 × 106K 
Plug-ins
Kc=(1.00 × 10−2)2 
(1.40 × 10−4)2 × 1.25 × 10−5= 4.08 × 108K 

For the given reaction: 
N2(g) + O2(g) → N2O(g) 
The equilibrium constant K_c is defined as follows: 
Firstly, we need to balance the given reaction: 2N2(g) + O2(g) → 2N2O(g) 
The equilibrium constant K_c is defined as  
Kc=[N2O] 
([N2] × [O2]) 
[N2] [O2] [N2O] 
follows: 
Kc=[N2O]a ([N2]b × [O2]c) 
where , , and are the molar  N2 O2 N2O 
concentrations of , , and respectively at  equilibrium. 
[N2] =2.80 × 10−4mol 
2.00L= 1.40 × 10−4M 
Kc 
Then plug these values into the formula for : Kc=(1.00 × 10−2) 
1.40 × 10−4 × 1.25 × 10−5= 5.71 × 106K 
where a,b,c are the coefficients of different  matters and [*] is the molarity of *. 
[N2] =2.80 × 10−4mol 
2.00L= 1.40 × 10−4M 
Kc 
Plugin the values and solving for numerically  we get  
Kc=(1.00 × 10−2)2 
(1.40 × 10−4)2 × 1.25 × 10−5= 4.08 × 108K

For the given reaction: 
Firstly, we need to balance the given reaction: 
N2(g) + O2(g) → N2O(g) 
Accurate domain knowledge 
2N2(g) + O2(g) → 2N2O(g) 
The equilibrium constant K_c is defined as follows: 
The equilibrium constant K_c is defined as  
Kc=[N2O] 
([N2] × [O2]) 
[N2] [O2] [N2O] 
follows: 
Precise scientific reasoningC 
Kc=[N2O]a ([N2]b × [O2]c) 
where , , and are the molar  N2 O2 N2O 
concentrations of , , and respectively at  equilibrium. 
where a,b,c are the coefficients of different  matters and [*] is the molarity of *. [N2] =2.80 × 10−4mol 
[N2] =2.80 × 10−4mol 
Symbolic/structured reasoning 
2.00L= 1.40 × 10−4M 
2.00L= 1.40 × 10−4M 
Kc 
Then plug these values into the formula for : Kc=(1.00 × 10−2) 
1.40 × 10−4 × 1.25 × 10−5= 5.71 × 106K 
Kc 
Plugin the values and solving for numerically  we get  
Kc=(1.00 × 10−2)2 
(1.40 × 10−4)2 × 1.25 × 10−5= 4.08 × 108K 
It’s really challenging task… 

For the given reaction: 
Firstly, we need to balance the given reaction: 
N2(g) + O2(g) → N2O(g) 
Accurate domain knowledge 
2N2(g) + O2(g) → 2N2O(g) 
The equilibrium constant K_c is defined as follows: 
The equilibrium constant K_c is defined as  
Kc=[N2O] 
([N2] × [O2]) 
[N2] [O2] [N2O] 
follows: 
Precise scientific reasoningC 
Kc=[N2O]a ([N2]b × [O2]c) 
where , , and are the molar  N2 O2 N2O 
concentrations of , , and respectively at  equilibrium. 
where a,b,c are the coefficients of different  matters and [*] is the molarity of *. [N2] =2.80 × 10−4mol 
[N2] =2.80 × 10−4mol 
Symbolic/structured reasoning 
2.00L= 1.40 × 10−4M 
2.00L= 1.40 × 10−4M 
Kc 
Plugin the values and solving for numerically  
Kc 
Then plug these values into the formula for : 
we get  
Fail on the task 
Kc=(1.00 × 10−2) 
1.40 × 10−4 × 1.25 × 10−5= 5.71 × 106K 
Undergrad students from top university 
Kc=(1.00 × 10−2)2 
(1.40 × 10−4)2 × 1.25 × 10−5= 4.08 × 108K Score: 27/100 
Recap on related works 
Self-Consistency  
(Wang et al., 2022):  
majority vote 
CoT (Wei et al.,  
2022)Self-Refine (Madaan  et al., 2023):  
feedback machinist 
Decomposed  
Prompting (Khot et  
al., 2022): modular
Recap on related works 
Self-Consistency  
(Wang et al., 2022):  
majority vote 
Task-wise: centered around arithmetic, commonsense, and  
logical reasoning problems. 
CoT (Wei et al.,  
2022)Self-Refine (Madaan  et al., 2023):  
feedback machinist 
Method-wise: Micro-level decomposition varying from sample  
to sample; Sequential prompting; 
Correct answers risk being swayed by feedback.
Decomposed  
Prompting (Khot et  
al., 2022): modular 
StructChem: 
A structural approach that elicits chemistry reasoning in LLMs • Overview 
Why not retrieval? 
Chemistry problem Structured instruction 
F0 R0Formulae generation Reasoning Process 
Iterative Review and Refinement  
with certain strategy 
Formulae generation with  step-by-step reasoning  
Answer 
StructChem: 
A structural approach that elicits chemistry reasoning in LLMs • Formulae generation with step-by-step reasoning 
Chemistry problem 
At a particular temperature, a  2.00L flask at equilibrium  contains 2.8 × 10−4 mol N2, … 
Collected Formulae 

Structured instruction 
Please provide a clear and step 
by-step solution for a scientific  
problem in the categories of … 
Reasoning steps 
[Formulae 1]  
2N2(g) + O2(g) → 2N2O(g) 
[Step 1] …compute the molarity of … 
[Formulae 2] … 
Confidence score: 0.9 
[Step 2] … 
F0 R0Confidence score: 0.7 
Structured instruction 
Please provide a clear and step-by-step solution for a scientific problem in the categories of Chemistry. The problem will specify the unit of  measurement, which should not be included in the answer. Express the final answer as a decimal number with three digits after the decimal point.  Conclude the answer by stating “The answer is therefore \\boxed{[ANSWER]}.” 
For each instance, you need to three things. Firstly, for "formulae retrieval", you need to identify the formulae explicitly and implicitly entailed in the  problem context. Then there is a "reasoning/calculation process" where you are required to reason step by step based on the identified formulae  and problem context. Finally, conclude the answer. For each problem, the output format should incorporate the following components in the  corresponding format: 
**Formulae retrieval: ** 
[Formula 1] (the formula required to solve the problem) [Formula 2] (the second formula required to solve the problem, if any) ... 
[Formula n] (the n-th formula required to solve the problem, if any) 
**Reasoning/calculation process:** 
[step 1] (the first step for solving this problem) 
..... 
[step n] (the n-th step for solving the problem, if any) 
**Answer conclusion:** 
[answer] The answer is therefore \\boxed{[ANSWER]}. 
To clearly explain the task, we provide the following example: 
Problem: 
Assume that all gases are perfect and that data refer to 298.15 K unless  otherwise stated. Calculate the change in chemical potential of a perfect  gas when its pressure is increased isothermally from $1.8 \\mathrm{~atm} $ to $29.5 \\mathrm{~atm}$ at $40^{\\circ} \\mathrm{C}$. The unit of the  answer is $\\mathrm{kJ} \\mathrm{mol}^{-1}$. 
Response: 
In order to solve this problem, we will use the formula for the change in  chemical potential \( \Delta \mu \) of a perfect gas due to a change in  pressure. Given that the temperature is constant (isothermal), the  chemical potential of a perfect gas is given by: 
……
StructChem: 
A structural approach that elicits chemistry reasoning in LLMs • Overview 
Chemistry problem Structured instruction 
F0 R0Formulae generation Reasoning Process 
Iterative Review and Refinement  
with certain strategy 
Formulae generation with  step-by-step reasoning  
Answer 
Iterative Review and Refinement F0 R0 Cf0 Cr0
F0 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) 
Kc=[N2O] 
([N2] × [O2]) 
Iterative Review and Refinement 
Confidence score C0: 0.9
Reviewer 1 
R0 F (0.9) 0 F0 → F1 
[Formulae 1] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O] 
F0 Confidence score C0: 0.9 
[Formulae 2] 
([N2] × [O2]) 
Iterative Review and Refinement 
Higher
F1 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O]a 
([N2]b × [O2]c) 
Confidence score C1: 0.95 
Reviewer 1 
F (0.9) 0 F0 → F1 
R0 
C1 ≥ C0 C1 < C0 
F (0.95) 1 
Discard F1 
F0 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) 
Kc=[N2O] 
([N2] × [O2]) 
Iterative Review and Refinement 
Confidence score C0: 0.9 
F1 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O]a 
([N2]b × [O2]c) 
Higher 
Confidence score C1: 0.95 
Reviewer 1 
F (0.9) 0 F0 → F1 
R0 
Lower 
[Formulae 1] 
N2(g) + O2(g) → N2O(g) 
C1 ≥ C0 C1 < C0 
F2Reviewer 2 
[Formulae 2] 
Kc=[N2O]a ([N2]b × [O2]c) 
M(g) =mol(g) 
Confidence score C2: 0.70
F (0.95) 1 
Discard F1 
[Formulae 3]  
C(g) 
F1 → F2 
C2 ≥ C1 C2 < C1 
Discard F2 
…… 
[Formulae 1] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O] 
F0 Confidence score C0: 0.9 
[Formulae 2] 
([N2] × [O2]) 
Iterative Review and Refinement 
Higher 
F1 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O]a 
([N2]b × [O2]c) 
Confidence score C1: 0.95 
Reviewer 1 
F (0.9) 0 F0 → F1 
R0 
Lower 
[Formulae 1] 
F2 
N2(g) + O2(g) → N2O(g) 
C1 ≥ C0 C1 < C0 
Reviewer 2 
[Formulae 2] 
Kc=[N2O]a ([N2]b × [O2]c) 
M(g) =mol(g) 
Confidence score C2: 0.70 
F (0.95) 1 
Discard F1 
Fn 
[Formulae 3]  
…… 
…… 
C(g) 
…… 
…… 

Reviewer n 
F1 → F2 
C2 ≥ C1 C2 < C1
Discard F2 
…… 
Fn 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O] 
([N2] × [O2]) 
Fn, R0 
[Formulae 3] … 
—————————————————————————— [Step 1] First calculate the molarity of each gas based on  
Iterative Review and Refinement 
Reviewer 1 Fn, R0
Formulae 3, … [Step 2] … 
Confidence score C0: 0.76 
Fn, R0 → Fn, R1 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O] 
([N2] × [O2]) 
Iterative Review and Refinement 
Fn, R0 
[Formulae 3] … 
—————————————————————————— 
[Step 1] First calculate the molarity of each gas based on  Formulae 3, … 
Reviewer 1 
F (0.76) n, R0 
[Step 2] … 
[Formulae 1] [Formulae 2] 
Confidence score C0: 0.76 
Higher 
2N2(g) + O2(g) → 2N2O(g) 
Kc=[N2O] 
Fn, R0 → Fn, R1 
C1 ≥ C0 
C1 < C0
Fn, R1 
([N2] × [O2]) 
[Formulae 3] … 
F (0.83) n, R1 Discard R1 
—————————————————————————— [Step 1] Based on the balanced equation in Formulae 1, … 
Reviewer 2 
[Step 2] … 
Confidence score C1: 0.83 
[Formulae 1] [Formulae 2] 
2N2(g) + O2(g) → 2N2O(g) Kc=[N2O] 
([N2] × [O2]) 
Iterative Review and Refinement 
Fn, R0 
[Formulae 3] … 
—————————————————————————— 
[Step 1] First calculate the molarity of each gas based on  Formulae 3, … 
Reviewer 1 
F (0.76) n, R0 
[Step 2] … 
[Formulae 1] [Formulae 2] 
Confidence score C0: 0.76 
Higher 
2N2(g) + O2(g) → 2N2O(g) 
Kc=[N2O] 
Fn, R0 → Fn, R1 
C1 ≥ C0 
C1 < C0 
Fn, R1 
([N2] × [O2]) 
[Formulae 3] … 
F (0.83) n, R1 Discard R1 
—————————————————————————— [Step 1] Based on the balanced equation in Formulae 1, … 
Reviewer 2 
Fn, R1 → Fn, R2 
[Step 2] … 
…… 
Fn, Rn 
Confidence score C1: 0.83 
…… 
Fn, Rn 
C2 ≥ C1
…… 

0 
F (0.9) 0 F0 → F1 
R0 
F (0.76) n, R0 Fn, R0 → Fn, R1 
0 
C1 ≥ C0 C1 < C0 
C1 ≥ C0 
F (0.95) 1 
F1 → F2 
C2 ≥ C1 C2 < C1 
Discard F1 
C1 < C0 
F (0.83) n, R1 Discard R1 Fn, R1 → Fn, R2 
n 
…… Fn 
Discard F2 
…… 
Fn, Rn 
C2 ≥ C1 
…… 
n
Therefore, the answer is …. 
Experiments

Benchmark performance (GPT-3.5) Zero-shot setting 
40 
40 


30 
30 
20 
20 
10 
10 
0 
0 
quan chemmc atkins matter avg 
Few-shot setting 


quan chemmc atkins matter avg 
Performance improvement on  
few-shot setting is even larger
Direct Reasoning System Instruction CoT Struct Chem 
Benchmark performance (GPT-4) Zero-shot setting 
60 
47.5 35 
22.5 10 


quan chemmc atkins matter avg 
Effective, average of 30%  
improvement 
60 
47.5 35 
22.5 10 
Few-shot setting 


quan chemmc atkins matter avg 
StructChem works on both  
GPT-3.5 and GPT-4
Direct Reasoning System Instruction CoT Struct Chem 
Validating reasoning quality 
Huge improvement over baselines.
Llama-2-13B-chat 
40 
40 


30 
30 
20 
20 
10 
10 
0 
0 
quan chemmc atkins matter avg 
Vicuna-13B 


quan chemmc atkins matter avg 
Zero-shot Inference Instuction 
CoT-finetuned 
StructChem-finetuned 
Teach smaller open-sourced models how to reason: ● Chemistry problems generated by GPT-4 as input ● Reasoning processes generated by StructChem as output  
Ablations Zero-shot setting 
Few-shot setting 
50 
60 


40 
50 
40 
30 
20 
30 
10 
20 
quan chemmc atkins matter avg 


quan chemmc atkins matter avg 
Effectiveness of all  components.
w/o confidence score w/o iterative review w/o review for Formulae StructChem 
Error analysis 
Formulae collection 
● Irrelevance: irrelevant formulae collected  
to solving the problem.  
● Incorrectness: incorrectness inherent in  
the formula itself.  
Reasoning  
● Reasoning error: errors made during the  
intermediate reasoning steps.  
● Calculation error: mathematical  
computation mistakes made during  
reasoning process.Irrelevance Incorrectness Reasoning error Calculation error
Error analysis 
Formulae collection 
● Principle error: formulae collected are  
LLMs are more likely to be irrelevant than  
not relevant to solving the problem.  
inaccurate 
● Factual error: incorrectness inherent in  the formula itself.  
Reasoning  
Complex reasoning is still the bottleneck. 
● Reasoning error: errors made during the  intermediate reasoning steps.  
● Calculation error: mathematical  Calculation errors are a significant issue as well. 
computation mistakes made during  reasoning process. 
Summary and discussions 
Formulae generation as domain knowledge retrieval.  
● Domain knowledge plays an important role in solving complex chemistry  questions. 
● Eliciting inherent domain knowledge in LLMs could be further improved by  incorporating retrieval systems.  
Fine-tuning smaller models as knowledge distillation.  
● Directly fine-tune open-source models with high-quality reasoning data can  achieve huge improvement against zero-shot inferences.  
● Future works could include designing strategies to transfer and distill reasoning  knowledge from LLMs to smaller LMs.
Summary 
(1) study the various ways the precise scientific reasoning can fail with frontier  LLMs  
(2) the importance of symbolic/structured reasoning 
(3) acknowledging that this type of precise reasoning remains to be a major  challenge, suggesting a more fundamental research into this direction
Thank you! 
CSE 156 NLP 75 
Pretraining
